"""
============================================================================
è—¥ç‰©è¾¨è­˜ç³»çµ± - å½±åƒè¾¨è­˜æ¨¡çµ„ (image_recognition.py)
============================================================================

ã€æª”æ¡ˆåŠŸèƒ½ã€‘
æ­¤æ¨¡çµ„æ˜¯ç³»çµ±çš„æ ¸å¿ƒè¾¨è­˜å¼•æ“ï¼Œä½¿ç”¨ OpenCV é€²è¡Œè—¥ç‰©åœ–ç‰‡çš„ç‰¹å¾µæå–èˆ‡æ¯”å°ã€‚

ã€ä¸»è¦åŠŸèƒ½ã€‘
1. åœ–ç‰‡é è™•ç†
   - èª¿æ•´åœ–ç‰‡å¤§å°ç‚ºæ¨™æº–å°ºå¯¸ (300x300)
   - CLAHE å°æ¯”åº¦å¢å¼·
   - é™å™ªè™•ç†

2. ç‰¹å¾µæå– (å››å¤§ç‰¹å¾µç¶­åº¦)
   - é¡è‰²ç‰¹å¾µ (æ¬Šé‡ 40%): HSV è‰²å½©ç›´æ–¹åœ– (18Ã—8Ã—8 bins)
   - å½¢ç‹€ç‰¹å¾µ (æ¬Šé‡ 30%): åœ“åº¦ã€é•·å¯¬æ¯”ã€è¼ªå»“åˆ†æ
   - ç´‹ç†ç‰¹å¾µ (æ¬Šé‡ 20%): LBP (Local Binary Pattern) ç´‹ç†ç‰¹å¾µ
   - å°å­—ç‰¹å¾µ (æ¬Šé‡ 10%): ORB ç‰¹å¾µé»åµæ¸¬ (500 å€‹ç‰¹å¾µé»)

3. ç›¸ä¼¼åº¦è¨ˆç®—
   - é¡è‰²: ç›´æ–¹åœ–ç›¸é—œä¿‚æ•¸ (Histogram Correlation)
   - å½¢ç‹€: æ­å¼è·é›¢è¨ˆç®—
   - ç´‹ç†: LBP ç›´æ–¹åœ–æ¯”å°
   - å°å­—: ORB ç‰¹å¾µé»åŒ¹é…

4. æ™ºæ…§éæ¿¾èˆ‡æ‡²ç½°æ©Ÿåˆ¶
   - é¡è‰²ç›¸ä¼¼åº¦ <35% â†’ 0.3x æ‡²ç½°, <50% â†’ 0.6x æ‡²ç½°
   - å½¢ç‹€ç›¸ä¼¼åº¦ <30% â†’ 0.5x æ‡²ç½°, <40% â†’ 0.7x æ‡²ç½°
   - æœ€ä½ç›¸ä¼¼åº¦é–€æª»: 15% (éæ¿¾ä½å“è³ªçµæœ)

5. é¡è‰²è‡ªå‹•æ¨è«–
   - æ”¯æ´ 11 ç¨®é¡è‰²: ç´…ã€æ©™ã€é»ƒã€ç¶ ã€è—ã€ç´«ã€ç²‰ç´…ã€è¤ã€ç™½ã€ç°ã€é»‘
   - ä½¿ç”¨ HSV è‰²å½©ç©ºé–“ç²¾ç¢ºåˆ¤æ–·

ã€æ¼”ç®—æ³•å„ªåŒ–ã€‘
- å¤šå±¤æ¬¡èƒŒæ™¯é®ç½©ç­–ç•¥ (éæ¿¾ç™½è‰²èƒŒæ™¯)
- è‡ªé©æ‡‰äºŒå€¼åŒ–è™•ç† (è™•ç†å…‰ç…§ä¸å‡)
- å½¢æ…‹å­¸æ“ä½œ (é–‰é‹ç®—å¡«è£œå­”æ´ã€é–‹é‹ç®—å»é™¤é›œè¨Š)
- ç‰¹å¾µå¿«å–æ©Ÿåˆ¶ (åŠ é€Ÿé‡è¤‡æŸ¥è©¢)
- å¤šåŸ·è¡Œç·’é è¼‰å…¥ (èƒŒæ™¯è¼‰å…¥è³‡æ–™åº«ç‰¹å¾µ)

ã€è¾¨è­˜æµç¨‹ã€‘
1. ä¸Šå‚³åœ–ç‰‡ â†’ é è™•ç† â†’ ç‰¹å¾µæå–
2. èˆ‡è³‡æ–™åº«ä¸­ 4775+ å¼µè—¥ç‰©åœ–ç‰‡æ¯”å°
3. è¨ˆç®—åŠ æ¬Šç›¸ä¼¼åº¦åˆ†æ•¸
4. å¥—ç”¨æ™ºæ…§éæ¿¾èˆ‡æ‡²ç½°æ©Ÿåˆ¶
5. å›å‚³å‰ 10 åæœ€ç›¸ä¼¼çš„è—¥ç‰©

ã€æ•ˆèƒ½è¡¨ç¾ã€‘
- é è¼‰å…¥å‰ 50 ç­†ç†±é–€è—¥ç‰©ç‰¹å¾µ
- å¹³å‡è¾¨è­˜æ™‚é–“: 2-5 ç§’
- ç›®æ¨™æº–ç¢ºç‡: >70%

ã€ä½¿ç”¨ç¯„ä¾‹ã€‘
    recognizer = DrugImageRecognizer()
    results = recognizer.recognize_drug("uploaded_image.jpg")

    for result in results:
        print(f"{result['chinese_name']}: {result['similarity']:.2f}%")

ã€æ³¨æ„äº‹é …ã€‘
- åœ–ç‰‡å»ºè­°: ç™½è‰²èƒŒæ™¯ã€è—¥ç‰©ç½®ä¸­ã€æ¸…æ™°ç…§æ˜
- å½¢ç‹€ç¯©é¸ä½¿ç”¨ç²¾ç¢ºåŒ¹é… (åœ“å½¢ â‰  æ©¢åœ“å½¢)
- é¡è‰²ç¯©é¸ä½¿ç”¨æ¨¡ç³ŠåŒ¹é… (é»ƒ å¯åŒ¹é… é»ƒè‰²)

ã€ä½œè€…ã€‘MUS_Project åœ˜éšŠ
ã€æ—¥æœŸã€‘2024-2025
============================================================================
"""

import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
import sqlite3
import threading


class DrugImageRecognizer:
    """
    è—¥ç‰©åœ–ç‰‡è¾¨è­˜å™¨ (åŸºæ–¼ç‰¹å¾µæ¯”å°æ–¹æ³•)

    æ ¸å¿ƒæŠ€è¡“:
    - å¤šåŸ·è¡Œç·’ç‰¹å¾µé è¼‰å…¥ï¼ŒåŠ å¿«é¦–æ¬¡è¾¨è­˜é€Ÿåº¦
    - ç‰¹å¾µå¿«å–æ©Ÿåˆ¶ï¼Œé¿å…é‡è¤‡è¨ˆç®—
    - æ”¯æ´å½¢ç‹€ã€é¡è‰²ç¯©é¸æ¢ä»¶
    - é€²åº¦å›å ±èˆ‡å–æ¶ˆæ©Ÿåˆ¶

    è¾¨è­˜æµç¨‹:
    1. è¼‰å…¥è³‡æ–™åº«ä¸­æ‰€æœ‰è—¥ç‰©åœ–ç‰‡çš„ä¸­ç¹¼è³‡æ–™
    2. èƒŒæ™¯åŸ·è¡Œç·’é å…ˆè¨ˆç®—è³‡æ–™åº«åœ–ç‰‡çš„ç‰¹å¾µ (é¡è‰²ã€å½¢ç‹€ã€ç´‹ç†)
    3. ä½¿ç”¨è€…ä¸Šå‚³åœ–ç‰‡å¾Œï¼Œæå–ä¸Šå‚³åœ–ç‰‡çš„ç‰¹å¾µ
    4. é€ä¸€æ¯”å°è³‡æ–™åº«åœ–ç‰‡ï¼Œè¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸
    5. å›å‚³ Top-K æœ€ç›¸ä¼¼çš„è—¥ç‰©å€™é¸

    æ•ˆèƒ½å„ªåŒ–:
    - ç‰¹å¾µé è¼‰å…¥: é¦–æ¬¡è¾¨è­˜éœ€ç­‰å¾…ç´„ 30-60 ç§’ï¼Œä¹‹å¾Œå³æ™‚éŸ¿æ‡‰
    - ç‰¹å¾µå¿«å–: å·²è¨ˆç®—çš„ç‰¹å¾µå­˜æ–¼è¨˜æ†¶é«”ï¼Œé¿å…é‡è¤‡é‹ç®—
    - ORB å¿«å–: åˆ»ç—•ç‰¹å¾µå–®ç¨å¿«å–ï¼Œé™ä½è¨˜æ†¶é«”ä½¿ç”¨
    """

    def __init__(
        self, db_path: str = "drug_recognition.db", photo_dir: str = "medicine_photos"
    ):
        """
        åˆå§‹åŒ–è—¥ç‰©åœ–ç‰‡è¾¨è­˜å™¨

        åƒæ•¸:
            db_path (str): SQLite è³‡æ–™åº«è·¯å¾‘ï¼Œé è¨­ "drug_recognition.db"
            photo_dir (str): è—¥ç‰©åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘ï¼Œé è¨­ "medicine_photos"

        èªªæ˜:
        - å»ºæ§‹å®Œæˆå¾Œæœƒè‡ªå‹•å•Ÿå‹•èƒŒæ™¯åŸ·è¡Œç·’é è¼‰ç‰¹å¾µ
        - é è¼‰æœŸé–“ä»å¯é€²è¡Œè¾¨è­˜ï¼Œä½†é€Ÿåº¦è¼ƒæ…¢
        - å»ºè­°åœ¨ç³»çµ±å•Ÿå‹•æ™‚åˆå§‹åŒ–æ­¤ç‰©ä»¶
        """
        self.db_path = db_path
        self.photo_dir = Path(photo_dir)
        self._image_records: List[Dict[str, str]] = []  # è—¥ç‰©åœ–ç‰‡ä¸­ç¹¼è³‡æ–™
        self._metadata_loaded = False  # ä¸­ç¹¼è³‡æ–™æ˜¯å¦å·²è¼‰å…¥
        # ç‰¹å¾µå¿«å–: filename -> (color_hist, shape_dict, lbp_hist)
        self._feature_cache: Dict[
            str, Tuple[np.ndarray, Dict[str, float], np.ndarray]
        ] = {}
        self._orb_cache: Dict[str, Optional[np.ndarray]] = {}  # ORB åˆ»ç—•ç‰¹å¾µå¿«å–
        self._features_loaded = False  # ç‰¹å¾µæ˜¯å¦å·²å…¨éƒ¨é è¼‰
        self._load_lock = threading.Lock()  # åŸ·è¡Œç·’é–ï¼Œé¿å…é‡è¤‡è¼‰å…¥
        self._computed_count = 0  # å·²è¨ˆç®—ç‰¹å¾µçš„åœ–ç‰‡æ•¸é‡
        self._orb = cv2.ORB_create(nfeatures=500)  # ORB ç‰¹å¾µåµæ¸¬å™¨ (åˆ»ç—•è¾¨è­˜ç”¨)
        # å•Ÿå‹•èƒŒæ™¯åŸ·è¡Œç·’é è¼‰ç‰¹å¾µ
        self._load_thread: Optional[threading.Thread] = threading.Thread(
            target=self._load_database_features, daemon=True
        )
        self._load_thread.start()

    def _load_image_metadata(self) -> None:
        """
        è¼‰å…¥æ‰€æœ‰è—¥ç‰©åœ–ç‰‡çš„ä¸­ç¹¼è³‡æ–™ (å¾è³‡æ–™åº«)

        åŠŸèƒ½:
        - è®€å– drugs å’Œ drug_images è³‡æ–™è¡¨çš„é—œè¯è³‡æ–™
        - å»ºç«‹è—¥ç‰© IDã€åç¨±ã€åœ–ç‰‡æª”åçš„å°æ‡‰æ¸…å–®
        - ä½¿ç”¨åŸ·è¡Œç·’é–ç¢ºä¿åªè¼‰å…¥ä¸€æ¬¡

        è¼‰å…¥è³‡æ–™åŒ…å«:
        - drug_id: è—¥ç‰© ID
        - chinese_name, english_name: ä¸­è‹±æ–‡åç¨±
        - license_number: è¨±å¯è­‰å­—è™Ÿ
        - shape, color: å¤–è§€ç‰¹å¾µ
        - special_dosage_form: ç‰¹æ®ŠåŠ‘å‹
        - image_filename: åœ–ç‰‡æª”å

        èªªæ˜:
        - æ­¤æ–¹æ³•æœƒåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­è‡ªå‹•å‘¼å«
        - è¼‰å…¥å¤±æ•—æ™‚æœƒå°å‡ºè­¦å‘Šè¨Šæ¯ï¼Œä½†ä¸æœƒä¸­æ–·ç¨‹å¼åŸ·è¡Œ
        """
        if self._metadata_loaded:
            return

        with self._load_lock:
            if self._metadata_loaded:
                return

            conn = None
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT DISTINCT d.id, d.chinese_name, d.english_name, d.license_number,
                           d.shape, d.color, d.special_dosage_form, i.image_filename
                    FROM drugs d
                    INNER JOIN drug_images i ON d.id = i.drug_id
                """
                )
                rows = cursor.fetchall()
                self._image_records = [
                    {
                        "drug_id": row[0],
                        "chinese_name": row[1],
                        "english_name": row[2],
                        "license_number": row[3],
                        "shape": row[4],
                        "color": row[5],
                        "special_dosage_form": row[6],
                        "image_filename": row[7],
                    }
                    for row in rows
                ]
                self._metadata_loaded = True
            except Exception as exc:
                print(f"âš ï¸ ç„¡æ³•è¼‰å…¥è³‡æ–™åº«åœ–ç‰‡æ¸…å–®: {exc}")
                self._image_records = []
            finally:
                try:
                    if conn:
                        conn.close()
                except Exception:
                    pass

    def _get_or_compute_features(
        self, record: Dict[str, str]
    ) -> Optional[Tuple[np.ndarray, Dict[str, float], np.ndarray]]:
        """å–å¾—æˆ–è¨ˆç®—æŒ‡å®šåœ–ç‰‡çš„ç‰¹å¾µ (é¡è‰²ç›´æ–¹åœ–ã€å½¢ç‹€å­—å…¸ã€LBPç´‹ç†)ã€‚"""

        filename = record["image_filename"]
        with self._load_lock:
            cached = self._feature_cache.get(filename)
        if cached is not None:
            return cached

        image_path = self.photo_dir / filename
        if not image_path.exists():
            return None

        db_img = self.preprocess_image(str(image_path), apply_denoise=False)
        if db_img is None:
            return None

        db_hist = self.extract_color_histogram(db_img)
        db_shape = self.extract_shape_features(db_img)
        db_lbp = self.extract_lbp_features(db_img)
        # å„²å­˜å®Œæ•´å½¢ç‹€ç‰¹å¾µï¼ˆcircularity å’Œ aspect_ratioï¼‰
        features = (db_hist, db_shape, db_lbp)

        with self._load_lock:
            self._feature_cache[filename] = features
            self._computed_count = len(self._feature_cache)

        total = len(self._image_records)
        if total and self._computed_count % 200 == 0:
            print(f"ğŸ“¸ å·²è¨ˆç®— {self._computed_count}/{total} å¼µè—¥å“åœ–ç‰‡ç‰¹å¾µ")

        return features

    def _get_or_compute_orb(
        self, filename: str, image_path: Path
    ) -> Optional[np.ndarray]:
        """å»¶é²è¨ˆç®—æŒ‡å®šåœ–ç‰‡çš„ ORB æè¿°å­ä¸¦å¿«å–ã€‚"""

        with self._load_lock:
            if filename in self._orb_cache:
                return self._orb_cache[filename]

        if not image_path.exists():
            with self._load_lock:
                self._orb_cache[filename] = None
            return None

        db_img = self.preprocess_image(str(image_path), apply_denoise=False)
        if db_img is None:
            with self._load_lock:
                self._orb_cache[filename] = None
            return None

        descriptors = self.extract_orb_descriptors(db_img)

        with self._load_lock:
            self._orb_cache[filename] = descriptors

        return descriptors

    def _match_filters(
        self,
        record: Dict[str, str],
        filter_shape: Optional[str],
        filter_color: Optional[str],
    ) -> bool:
        """
        æª¢æŸ¥è—¥ç‰©è¨˜éŒ„æ˜¯å¦ç¬¦åˆå½¢ç‹€å’Œé¡è‰²ç¯©é¸æ¢ä»¶

        æ³¨æ„ï¼šå½¢ç‹€ä½¿ç”¨ç²¾ç¢ºåŒ¹é…ï¼Œé¡è‰²ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…

        Args:
            record: è—¥ç‰©è¨˜éŒ„å­—å…¸
            filter_shape: ç¯©é¸å½¢ç‹€ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
            filter_color: ç¯©é¸é¡è‰²ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰

        Returns:
            True å¦‚æœç¬¦åˆæ‰€æœ‰æŒ‡å®šçš„ç¯©é¸æ¢ä»¶ï¼Œå¦å‰‡ False
        """
        # æª¢æŸ¥å½¢ç‹€ï¼ˆç²¾ç¢ºåŒ¹é…ï¼Œé¿å…ã€Œåœ“å½¢ã€åŒ¹é…åˆ°ã€Œæ©¢åœ“å½¢ã€ï¼‰
        if filter_shape:
            drug_shape = record.get("shape", "")
            if not drug_shape or drug_shape != filter_shape:
                return False

        # æª¢æŸ¥é¡è‰²ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼Œå…è¨±ã€Œé»ƒã€åŒ¹é…ã€Œé»ƒè‰²ã€ï¼‰
        if filter_color:
            drug_color = record.get("color", "")
            if not drug_color or filter_color not in drug_color:
                return False

        return True

    def _infer_color_labels(self, image: np.ndarray) -> List[str]:
        """
        ç”±åœ–ç‰‡æ¨ä¼°é¡è‰²æ¨™ç±¤ï¼ˆä¸­æ–‡ï¼‰ï¼Œå›å‚³å€™é¸æ¨™ç±¤åˆ—è¡¨ï¼Œç”¨æ–¼ç¸®å°æ¯”å°ç¯„åœã€‚

        å¯èƒ½å›å‚³ï¼š['ç™½', 'ç™½è‰²']ã€['ç´…', 'ç´…è‰²']ã€['ç²‰', 'ç²‰ç´…', 'ç²‰ç´…è‰²']ã€['é»ƒ', 'é»ƒè‰²']ã€
                 ['ç¶ ', 'ç¶ è‰²']ã€['è—', 'è—è‰²']ã€['ç´«', 'ç´«è‰²']ã€['æ©™', 'æ©˜', 'æ©™è‰²', 'æ©˜è‰²']ã€
                 ['é»‘', 'é»‘è‰²']ã€['ç°', 'ç°è‰²']ã€['æ£•', 'å’–å•¡', 'æ£•è‰²', 'å’–å•¡è‰²']
        """
        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            h = hsv[:, :, 0].astype(np.float32)
            s = hsv[:, :, 1].astype(np.float32)
            v = hsv[:, :, 2].astype(np.float32)

            mean_s = float(np.mean(s))
            mean_v = float(np.mean(v))
            mean_h = float(np.mean(h))  # 0~180

            # ä½é£½å’Œåº¦ï¼šé»‘/ç™½/ç°
            if mean_s < 30:
                if mean_v > 180:
                    return ["ç™½", "ç™½è‰²"]
                elif mean_v < 60:
                    return ["é»‘", "é»‘è‰²"]
                else:
                    return ["ç°", "ç°è‰²"]

            # ç²‰ç´…è‰²/ç²‰è‰²ï¼šç´…è‰²ç³»ä½†é£½å’Œåº¦è¼ƒä½ã€äº®åº¦è¼ƒé«˜
            if (mean_h <= 10 or mean_h >= 160) and 30 <= mean_s < 100 and mean_v > 150:
                return ["ç²‰", "ç²‰ç´…", "ç²‰ç´…è‰²", "ç²‰è‰²"]

            # ä»¥ Hue åˆ¤æ–·è‰²èª¿
            if mean_h <= 10 or mean_h >= 160:
                return ["ç´…", "ç´…è‰²", "ç²‰", "ç²‰ç´…"]  # ç´…è‰²ä¹ŸåŒ…å«ç²‰ç´…å¯èƒ½
            if 11 <= mean_h <= 25:
                return ["æ©™", "æ©˜", "æ©™è‰²", "æ©˜è‰²"]
            if 26 <= mean_h <= 34:
                return ["é»ƒ", "é»ƒè‰²"]
            if 35 <= mean_h <= 85:
                return ["ç¶ ", "ç¶ è‰²"]
            if 86 <= mean_h <= 125:
                return ["è—", "è—è‰²"]
            if 126 <= mean_h <= 159:
                return ["ç´«", "ç´«è‰²"]

            # å…¶ä»–è‰²èª¿è¦–ç‚ºæ£•/å’–å•¡
            return ["æ£•", "å’–å•¡", "æ£•è‰²", "å’–å•¡è‰²"]
        except Exception:
            return []

    def _load_database_features(self) -> None:
        """èƒŒæ™¯è¼‰å…¥åœ–ç‰‡æ¸…å–®ä¸¦é å…ˆè¨ˆç®—å°‘é‡ç‰¹å¾µã€‚"""

        self._load_image_metadata()

        total = len(self._image_records)
        preload_cap = min(50, total)
        loaded = 0

        if preload_cap:
            for record in self._image_records[:preload_cap]:
                if self._get_or_compute_features(record) is not None:
                    loaded += 1

        with self._load_lock:
            self._features_loaded = loaded >= total and total > 0

        if total:
            print(
                f"âœ… å·²é å…ˆè¼‰å…¥ {loaded}/{total} ç­†è—¥å“åœ–ç‰‡ç‰¹å¾µï¼ˆå…¶é¤˜å°‡æ–¼æŸ¥è©¢æ™‚å‹•æ…‹è¨ˆç®—ï¼‰"
            )
        else:
            print("âš ï¸ æœªåœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°å¯ç”¨çš„è—¥å“åœ–ç‰‡")

    def reload_feature_cache(self, async_load: bool = False) -> None:
        """é‡æ–°æ•´ç†å¿«å–ï¼Œæ”¯æ´èƒŒæ™¯è¼‰å…¥ã€‚"""

        def _reload():
            with self._load_lock:
                self._features_loaded = False
                self._feature_cache.clear()
                self._metadata_loaded = False
                self._computed_count = 0
            self._load_database_features()

        if async_load:
            threading.Thread(target=_reload, daemon=True).start()
        else:
            _reload()

    def preprocess_image(
        self, image_path: str, apply_denoise: bool = True
    ) -> Optional[np.ndarray]:
        """
        é è™•ç†åœ–ç‰‡ï¼šèª¿æ•´å¤§å°ã€å»å™ªã€å¢å¼·å°æ¯”åº¦

        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            apply_denoise: æ˜¯å¦æ‡‰ç”¨é™å™ªï¼ˆä¸Šå‚³åœ–ç‰‡å»ºè­°é–‹å•Ÿï¼‰

        Returns:
            è™•ç†å¾Œçš„åœ–ç‰‡é™£åˆ—ï¼Œå¤±æ•—è¿”å› None
        """
        try:
            # ä½¿ç”¨ cv2.imdecode è™•ç†ä¸­æ–‡è·¯å¾‘
            import numpy as np

            # è®€å–åœ–ç‰‡ï¼ˆæ”¯æ´ä¸­æ–‡è·¯å¾‘ï¼‰
            with open(image_path, "rb") as f:
                image_data = f.read()
            nparr = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if img is None:
                return None

            # èª¿æ•´å¤§å°ï¼ˆæ¨™æº–åŒ–ï¼‰
            img = cv2.resize(img, (300, 300))

            # å¢å¼·å°æ¯”åº¦ï¼ˆCLAHE - Contrast Limited Adaptive Histogram Equalizationï¼‰
            # å°‡ BGR è½‰ç‚º LAB è‰²å½©ç©ºé–“ï¼Œåªå°äº®åº¦é€šé“åšç›´æ–¹åœ–å‡è¡¡åŒ–
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            img = cv2.merge([l, a, b])
            img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)

            # é™å™ªé‹ç®—æˆæœ¬é«˜ï¼Œåƒ…é‡å°ä¸Šå‚³åœ–ç‰‡åŸ·è¡Œ
            if apply_denoise:
                img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)

            return img
        except Exception as e:
            print(f"åœ–ç‰‡é è™•ç†å¤±æ•—: {e}")
            return None

    def extract_color_histogram(self, image: np.ndarray) -> np.ndarray:
        """
        æå–é¡è‰²ç›´æ–¹åœ–ç‰¹å¾µï¼ˆå„ªåŒ–ç‰ˆï¼šå°ˆæ³¨æ–¼è—¥ç‰©ä¸»é«”ï¼Œå¢å¼·é¡è‰²å€åˆ†åº¦ï¼‰

        Args:
            image: åœ–ç‰‡é™£åˆ—

        Returns:
            é¡è‰²ç›´æ–¹åœ–ç‰¹å¾µå‘é‡
        """
        # è½‰æ›åˆ° HSV è‰²å½©ç©ºé–“
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # å¤šå±¤æ¬¡é®ç½©ç­–ç•¥
        # 1. åŸºæœ¬é®ç½©ï¼šéæ¿¾ç´”ç™½èƒŒæ™¯
        mask1 = cv2.inRange(hsv, np.array([0, 0, 0]), np.array([180, 255, 250]))

        # 2. æ’é™¤ç´”ç™½å€åŸŸï¼ˆV > 245 ä¸” S < 20ï¼‰
        white_mask = cv2.inRange(hsv, np.array([0, 0, 245]), np.array([180, 20, 255]))
        mask = cv2.bitwise_and(mask1, cv2.bitwise_not(white_mask))

        # å¦‚æœæœ‰æ•ˆå€åŸŸå¤ªå°ï¼ˆ< 10%ï¼‰ï¼Œä½¿ç”¨æ•´å¼µåœ–
        valid_pixels = cv2.countNonZero(mask)
        total_pixels = image.shape[0] * image.shape[1]
        if valid_pixels < total_pixels * 0.1:
            mask = None

        # ä½¿ç”¨æ›´ç´°ç·»çš„åˆ†ç®±ä¾†æé«˜é¡è‰²å€åˆ†åº¦
        # H: 18 bins (æ¯ 10 åº¦), S: 8 bins, V: 8 bins
        hist = cv2.calcHist(
            [hsv],
            [0, 1, 2],
            mask,
            [18, 8, 8],  # å¢åŠ è‰²ç›¸åˆ†ç®±ä»¥æé«˜é¡è‰²æ•æ„Ÿåº¦
            [0, 180, 0, 256, 0, 256],
        )

        # æ­£è¦åŒ–
        hist = cv2.normalize(hist, hist).flatten()

        return hist

    def extract_shape_features(self, image: np.ndarray) -> Dict[str, float]:
        """
        æå–å½¢ç‹€ç‰¹å¾µï¼ˆå„ªåŒ–ç‰ˆï¼šæ›´å¥½è™•ç†å¸¶å­”è—¥ç‰©ï¼‰

        Args:
            image: åœ–ç‰‡é™£åˆ—

        Returns:
            å½¢ç‹€ç‰¹å¾µå­—å…¸
        """
        # è½‰ç‚ºç°éš
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # é«˜æ–¯æ¨¡ç³Šæ¸›å°‘é›œè¨Š
        gray = cv2.GaussianBlur(gray, (5, 5), 0)

        # è‡ªé©æ‡‰äºŒå€¼åŒ–ï¼ˆæ›´å¥½è™•ç†å…‰ç…§ä¸å‡ï¼‰
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
        )

        # å½¢æ…‹å­¸æ“ä½œï¼šé–‰é‹ç®—å¡«è£œå°å­”æ´ï¼Œé–‹é‹ç®—å»é™¤é›œè¨Š
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)

        # å°‹æ‰¾è¼ªå»“
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        if not contours:
            return {"area": 0, "perimeter": 0, "circularity": 0, "aspect_ratio": 1.0}

        # é¸æ“‡æœ€å¤§çš„è¼ªå»“ï¼ˆå‡è¨­ç‚ºè—¥ç‰©ä¸»é«”ï¼‰
        contour = max(contours, key=cv2.contourArea)

        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)

        # è¨ˆç®—åœ“åº¦ï¼ˆ4Ï€ Ã— é¢ç© / å‘¨é•·Â²ï¼‰
        if perimeter > 0:
            circularity = 4 * np.pi * area / (perimeter * perimeter)
        else:
            circularity = 0

        # è¨ˆç®—é•·å¯¬æ¯”ï¼ˆç”¨æ–¼å€åˆ†åœ“å½¢ã€æ©¢åœ“ã€é•·æ¢å½¢ï¼‰
        rect = cv2.minAreaRect(contour)
        width, height = rect[1]
        if width > 0 and height > 0:
            aspect_ratio = max(width, height) / min(width, height)
        else:
            aspect_ratio = 1.0

        return {
            "area": float(area),
            "perimeter": float(perimeter),
            "circularity": float(circularity),
            "aspect_ratio": float(aspect_ratio),
        }

        # å–æœ€å¤§è¼ªå»“
        main_contour = max(contours, key=cv2.contourArea)

        # è¨ˆç®—ç‰¹å¾µ
        area = cv2.contourArea(main_contour)
        perimeter = cv2.arcLength(main_contour, True)
        circularity = 4 * np.pi * area / (perimeter**2) if perimeter > 0 else 0

        return {"area": area, "perimeter": perimeter, "circularity": circularity}

    def extract_orb_descriptors(self, image: np.ndarray) -> Optional[np.ndarray]:
        """æå– ORB ç‰¹å¾µæè¿°å­ä»¥è¾¨è­˜è—¥éŒ åˆ»å°ã€‚"""

        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            keypoints, descriptors = self._orb.detectAndCompute(gray, None)
            if descriptors is None or len(descriptors) == 0:
                return None
            return descriptors
        except Exception as exc:
            print(f"ORB ç‰¹å¾µæå–å¤±æ•—: {exc}")
            return None

    def extract_lbp_features(
        self, image: np.ndarray, radius: int = 1, n_points: int = 8
    ) -> np.ndarray:
        """
        æå– LBP (Local Binary Pattern) ç´‹ç†ç‰¹å¾µï¼ˆé«˜é€Ÿå‘é‡åŒ–ç‰ˆæœ¬ï¼‰

        èªªæ˜ï¼š
        - å°‡ç°éšåœ–ç¸®æ”¾è‡³ 128x128ï¼Œä½¿ç”¨ 8 é„°åŸŸã€åŠå¾‘ 1 çš„ç¶“å…¸ LBPã€‚
        - ä»¥ numpy ä½å…ƒé‹ç®—è¨ˆç®—ï¼Œä¸ä½¿ç”¨å·¢ç‹€ Python è¿´åœˆï¼Œå¤§å¹…é™ä½å»¶é²ã€‚

        Args:
            image: åœ–ç‰‡é™£åˆ—
            radius: LBP åŠå¾‘ï¼ˆåƒ…æ”¯æ´ 1ï¼Œç”¨æ–¼å¿«é€Ÿé‹ç®—ï¼‰
            n_points: é„°åŸŸé»æ•¸ï¼ˆåƒ…æ”¯æ´ 8ï¼‰

        Returns:
            é•·åº¦ 256 çš„ LBP ç›´æ–¹åœ–ï¼ˆå·²æ­£è¦åŒ–ï¼‰
        """
        try:
            # è½‰ç‚ºç°éšä¸¦ç¸®å°å°ºå¯¸ä»¥é™ä½é‹ç®—é‡
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            gray = cv2.resize(gray, (128, 128), interpolation=cv2.INTER_AREA)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)

            if radius != 1 or n_points != 8:
                # ç‚ºä¿æŒé€Ÿåº¦èˆ‡ç©©å®šæ€§ï¼Œæš«æ™‚åƒ…æ”¯æ´ (radius=1, n_points=8)
                radius = 1
                n_points = 8

            # å…§éƒ¨å€åŸŸï¼ˆé¿å…é‚Šç•Œï¼‰
            c = gray[1:-1, 1:-1]
            codes = np.zeros_like(c, dtype=np.uint8)

            # 8 å€‹é„°å±…ä½ç§»ï¼ˆé †æ™‚é‡ï¼‰
            neighbors = [
                gray[0:-2, 0:-2],  # (-1,-1)
                gray[0:-2, 1:-1],  # (-1, 0)
                gray[0:-2, 2:],  # (-1,+1)
                gray[1:-1, 2:],  # ( 0,+1)
                gray[2:, 2:],  # (+1,+1)
                gray[2:, 1:-1],  # (+1, 0)
                gray[2:, 0:-2],  # (+1,-1)
                gray[1:-1, 0:-2],  # ( 0,-1)
            ]

            for bit, n in enumerate(neighbors):
                codes |= (n >= c).astype(np.uint8) << bit

            # è¨ˆç®—ç›´æ–¹åœ–ä¸¦æ­£è¦åŒ–
            hist, _ = np.histogram(codes.ravel(), bins=256, range=(0, 256))
            hist = hist.astype(np.float32)
            s = hist.sum()
            if s > 0:
                hist /= s

            return hist

        except Exception as e:
            print(f"LBP ç‰¹å¾µæå–å¤±æ•—: {e}")
            return np.zeros(256, dtype=np.float32)

    def extract_mark_features(self, mark_text: str) -> str:
        """
        æå–ä¸¦æ¨™æº–åŒ–åˆ»ç—•ç‰¹å¾µæ–‡å­—

        Args:
            mark_text: è—¥ç‰©åˆ»ç—•æè¿°æ–‡å­—

        Returns:
            æ¨™æº–åŒ–çš„åˆ»ç—•ç‰¹å¾µå­—ä¸²
        """
        if not mark_text or mark_text == "ç„¡" or mark_text == "None":
            return ""

        # ç§»é™¤ç©ºç™½å’Œæ¨™é»ç¬¦è™Ÿ,è½‰ç‚ºå¤§å¯«
        import re

        mark_text = mark_text.upper()
        mark_text = re.sub(r"[^\w\s]", "", mark_text)
        mark_text = re.sub(r"\s+", "", mark_text)

        return mark_text

    def calculate_mark_similarity(self, mark1: str, mark2: str) -> float:
        """
        è¨ˆç®—å…©å€‹åˆ»ç—•æè¿°çš„ç›¸ä¼¼åº¦

        Args:
            mark1: ç¬¬ä¸€å€‹åˆ»ç—•æè¿°
            mark2: ç¬¬äºŒå€‹åˆ»ç—•æè¿°

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
        """
        m1 = self.extract_mark_features(mark1)
        m2 = self.extract_mark_features(mark2)

        if not m1 or not m2:
            return 0.0

        if m1 == m2:
            return 1.0

        # ä½¿ç”¨åºåˆ—åŒ¹é…è¨ˆç®—ç›¸ä¼¼åº¦
        from difflib import SequenceMatcher

        matcher = SequenceMatcher(None, m1, m2)
        return matcher.ratio()

    def calculate_similarity(self, hist1: np.ndarray, hist2: np.ndarray) -> float:
        """
        è¨ˆç®—å…©å€‹ç›´æ–¹åœ–çš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ç›¸é—œæ€§ï¼‰

        Args:
            hist1: ç¬¬ä¸€å€‹ç›´æ–¹åœ–
            hist2: ç¬¬äºŒå€‹ç›´æ–¹åœ–

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
        """
        # ä½¿ç”¨ç›¸é—œæ€§æ–¹æ³•
        similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)

        # è½‰æ›åˆ° 0-1 ç¯„åœ
        return max(0, similarity)

    def calculate_orb_similarity(
        self, descriptors1: Optional[np.ndarray], descriptors2: Optional[np.ndarray]
    ) -> float:
        """è¨ˆç®— ORB æè¿°å­çš„ç›¸ä¼¼åº¦ï¼Œå€¼åŸŸ 0-1ã€‚"""

        if descriptors1 is None or descriptors2 is None:
            return 0.0

        try:
            matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
            matches = matcher.knnMatch(descriptors1, descriptors2, k=2)
        except cv2.error as exc:
            print(f"ORB æ¯”å°å¤±æ•—: {exc}")
            return 0.0

        good_matches = 0
        for pair in matches:
            if len(pair) < 2:
                continue
            m, n = pair
            if m.distance < 0.75 * n.distance:
                good_matches += 1

        max_possible = min(len(descriptors1), len(descriptors2))
        if max_possible == 0:
            return 0.0

        return good_matches / max_possible

    def calculate_lbp_similarity(self, lbp1: np.ndarray, lbp2: np.ndarray) -> float:
        """
        è¨ˆç®—å…©å€‹ LBP ç›´æ–¹åœ–çš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨å¡æ–¹è·é›¢ï¼‰

        Args:
            lbp1: ç¬¬ä¸€å€‹ LBP ç›´æ–¹åœ–
            lbp2: ç¬¬äºŒå€‹ LBP ç›´æ–¹åœ–

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
        """
        try:
            # ä½¿ç”¨å¡æ–¹è·é›¢
            chi_square = 0.0
            for i in range(len(lbp1)):
                if lbp1[i] + lbp2[i] > 0:
                    chi_square += ((lbp1[i] - lbp2[i]) ** 2) / (lbp1[i] + lbp2[i])

            # è½‰æ›ç‚ºç›¸ä¼¼åº¦ (è·é›¢è¶Šå°,ç›¸ä¼¼åº¦è¶Šé«˜)
            # ä½¿ç”¨æŒ‡æ•¸å‡½æ•¸å°‡è·é›¢è½‰æ›ç‚º 0-1 ç¯„åœçš„ç›¸ä¼¼åº¦
            similarity = np.exp(-chi_square / 2)

            return float(max(0.0, min(1.0, similarity)))

        except Exception as e:
            print(f"LBP ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

    def recognize_drug(
        self,
        uploaded_image_path: str,
        top_k: int = 5,
        filter_shape: Optional[str] = None,
        filter_color: Optional[str] = None,
        hooks: Optional[Dict[str, Any]] = None,
    ) -> List[Dict]:
        """
        è¾¨è­˜ä¸Šå‚³çš„è—¥ç‰©åœ–ç‰‡ (ä¸»è¦è¾¨è­˜æ–¹æ³•)

        è¾¨è­˜æµç¨‹:
        1. è¼‰å…¥ä¸¦é è™•ç†ä¸Šå‚³çš„åœ–ç‰‡
        2. æå–ä¸Šå‚³åœ–ç‰‡çš„ 4 ç¨®ç‰¹å¾µ (é¡è‰²ã€å½¢ç‹€ã€ç´‹ç†ã€åˆ»ç—•)
        3. æ ¹æ“šç¯©é¸æ¢ä»¶æˆ–è‡ªå‹•é¡è‰²æ¨ä¼°ç¸®å°å€™é¸ç¯„åœ
        4. é€ä¸€æ¯”å°è³‡æ–™åº«ä¸­çš„è—¥ç‰©åœ–ç‰‡
        5. è¨ˆç®—ç¶œåˆç›¸ä¼¼åº¦åˆ†æ•¸ (4 ç¨®ç‰¹å¾µåŠ æ¬Šå¹³å‡)
        6. å¥—ç”¨æ‡²ç½°æ©Ÿåˆ¶ (å½¢ç‹€/é¡è‰²ä¸ç¬¦æœƒæ‰£åˆ†)
        7. å›å‚³ Top-K æœ€ç›¸ä¼¼çš„è—¥ç‰©å€™é¸

        ç‰¹å¾µæ¬Šé‡åˆ†é…:
        - é¡è‰²ç›¸ä¼¼åº¦: 40% (ä¸»è¦ç¯©é¸ä¾æ“š)
        - å½¢ç‹€ç›¸ä¼¼åº¦: 30% (åœ“åº¦ 70% + é•·å¯¬æ¯” 30%)
        - ç´‹ç†ç›¸ä¼¼åº¦: 20% (LBP ç‰¹å¾µ)
        - åˆ»ç—•ç›¸ä¼¼åº¦: 10% (ORB ç‰¹å¾µé»æ¯”å°)

        è‡ªå‹•å„ªåŒ–æ©Ÿåˆ¶:
        - è‡ªå‹•é¡è‰²æ¨ä¼°: æœªæŒ‡å®šç¯©é¸æ¢ä»¶æ™‚ï¼Œå¾åœ–ç‰‡æ¨ä¼°é¡è‰²ä¸¦ç¸®å°å€™é¸ç¯„åœ
        - å»¶é²è¨ˆç®—: ORB åˆ»ç—•ç‰¹å¾µåƒ…åœ¨é¡è‰²ç›¸ä¼¼åº¦ >= 0.3 æ™‚æ‰è¨ˆç®—ï¼Œç¯€çœé‹ç®—
        - æ‡²ç½°æ©Ÿåˆ¶: å½¢ç‹€æˆ–é¡è‰²å®Œå…¨ä¸ç¬¦æ™‚ï¼Œç›¸ä¼¼åº¦æ‰£æ¸› 30-50%

        åƒæ•¸:
            uploaded_image_path (str): ä¸Šå‚³åœ–ç‰‡çš„æª”æ¡ˆè·¯å¾‘
            top_k (int): å›å‚³å‰ K åå€™é¸ï¼Œé è¨­ 5
            filter_shape (str): å½¢ç‹€ç¯©é¸æ¢ä»¶ (é¸å¡«ï¼Œä¾‹å¦‚: "åœ“å½¢")
            filter_color (str): é¡è‰²ç¯©é¸æ¢ä»¶ (é¸å¡«ï¼Œä¾‹å¦‚: "ç™½è‰²")
            hooks (dict): é€²åº¦å›å ±èˆ‡å–æ¶ˆæ©Ÿåˆ¶çš„ callback å‡½æ•¸
                - on_progress(done, total): å›å ±é€²åº¦
                - is_cancelled(): æª¢æŸ¥æ˜¯å¦å–æ¶ˆ

        å›å‚³:
            List[Dict]: Top-K è¾¨è­˜çµæœï¼Œæ¯ç­†åŒ…å«:
                - drug_id: è—¥ç‰© ID
                - chinese_name: ä¸­æ–‡åç¨±
                - similarity: ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
                - similarity_percent: ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”
                - color_similarity, shape_similarity, ...: å„é …ç‰¹å¾µç›¸ä¼¼åº¦

        ç¯„ä¾‹:
            results = recognizer.recognize_drug(
                "uploads/pill.jpg",
                top_k=10,
                filter_color="ç™½è‰²"
            )

        æ³¨æ„:
        - é¦–æ¬¡è¾¨è­˜éœ€ç­‰å¾…èƒŒæ™¯åŸ·è¡Œç·’å®Œæˆç‰¹å¾µé è¼‰å…¥ (ç´„ 30-60 ç§’)
        - å¾ŒçºŒè¾¨è­˜å³æ™‚éŸ¿æ‡‰ (é€šå¸¸ < 1 ç§’)
        - ç¯©é¸æ¢ä»¶æœƒé¡¯è‘—å½±éŸ¿çµæœæº–ç¢ºåº¦ï¼Œå»ºè­°æä¾›æº–ç¢ºçš„å½¢ç‹€/é¡è‰²
        """
        import time

        t0 = time.time()

        # è§£åŒ… hooks (é€²åº¦å›å ±èˆ‡å–æ¶ˆæ©Ÿåˆ¶)
        on_progress = None
        is_cancelled = None
        if isinstance(hooks, dict):
            on_progress = hooks.get("on_progress")
            is_cancelled = hooks.get("is_cancelled")
            if not callable(on_progress):
                on_progress = None
            if not callable(is_cancelled):
                is_cancelled = None

        # é è™•ç†ä¸Šå‚³çš„åœ–ç‰‡ (èª¿æ•´å¤§å°ã€å»å™ªç­‰)
        uploaded_img = self.preprocess_image(uploaded_image_path)
        if uploaded_img is None:
            return []

        # æå–ä¸Šå‚³åœ–ç‰‡çš„ 4 ç¨®ç‰¹å¾µ
        uploaded_hist = self.extract_color_histogram(uploaded_img)  # é¡è‰²ç›´æ–¹åœ–
        uploaded_shape = self.extract_shape_features(uploaded_img)  # å½¢ç‹€ç‰¹å¾µ
        uploaded_orb = self.extract_orb_descriptors(uploaded_img)  # ORB åˆ»ç—•ç‰¹å¾µ
        uploaded_lbp = self.extract_lbp_features(uploaded_img)  # LBP ç´‹ç†ç‰¹å¾µ

        # è¼‰å…¥è³‡æ–™åº«è—¥ç‰©åœ–ç‰‡çš„ä¸­ç¹¼è³‡æ–™
        self._load_image_metadata()

        if not self._image_records:
            return []

        # é å…ˆéæ¿¾ç¬¦åˆå½¢ç‹€/é¡è‰²æ¢ä»¶çš„è—¥ç‰©è¨˜éŒ„
        filtered_records = self._image_records
        if filter_shape or filter_color:
            # ä½¿ç”¨è€…æŒ‡å®šç¯©é¸æ¢ä»¶
            filtered_records = [
                record
                for record in self._image_records
                if self._match_filters(record, filter_shape, filter_color)
            ]
            print(
                f"ğŸ“‹ å¥—ç”¨ç¯©é¸æ¢ä»¶å¾Œï¼Œå‰©é¤˜ {len(filtered_records)}/{len(self._image_records)} ç­†è—¥ç‰©"
            )
        else:
            # æœªæŒ‡å®šç¯©é¸æ™‚ï¼Œä¾æ“šåœ–ç‰‡è‡ªå‹•æ¨ä¼°é¡è‰²ï¼Œç¸®å°æœå°‹ç©ºé–“
            auto_colors = self._infer_color_labels(uploaded_img)
            if auto_colors:
                filtered_records = [
                    r
                    for r in self._image_records
                    if any(lbl in (r.get("color") or "") for lbl in auto_colors)
                ]
                print(
                    f"ğŸ¯ è‡ªå‹•æ¨ä¼°é¡è‰² {auto_colors}ï¼Œå€™é¸ç¸®å°ç‚º {len(filtered_records)}/{len(self._image_records)} ç­†"
                )

        if not filtered_records:
            print("âš ï¸  æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è—¥ç‰©")
            return []

        # ç²å–æ‰€æœ‰æœ‰åœ–ç‰‡çš„è—¥ç‰©
        results = []
        total_candidates = len(filtered_records)
        if on_progress:
            try:
                on_progress(0, total_candidates)
            except Exception:
                pass

        for idx, record in enumerate(filtered_records, start=1):
            if is_cancelled and is_cancelled():
                print("ğŸ›‘ æ”¶åˆ°å–æ¶ˆä¿¡è™Ÿï¼Œæå‰çµæŸæ¯”å°")
                break
            features = self._get_or_compute_features(record)
            if features is None:
                continue

            db_hist, db_shape, db_lbp = features

            # è¨ˆç®—ç›¸ä¼¼åº¦
            color_similarity = self.calculate_similarity(uploaded_hist, db_hist)

            # å½¢ç‹€ç›¸ä¼¼åº¦ï¼ˆç¶œåˆåœ“åº¦å’Œé•·å¯¬æ¯”ï¼‰
            circularity_sim = 1 - abs(
                uploaded_shape["circularity"] - db_shape.get("circularity", 0.0)
            )
            circularity_sim = max(0.0, circularity_sim)

            aspect_ratio_sim = (
                1
                - abs(
                    uploaded_shape["aspect_ratio"] - db_shape.get("aspect_ratio", 1.0)
                )
                / 2.0
            )
            aspect_ratio_sim = max(0.0, min(1.0, aspect_ratio_sim))

            # ç¶œåˆå½¢ç‹€ç›¸ä¼¼åº¦ï¼ˆåœ“åº¦70% + é•·å¯¬æ¯”30%ï¼‰
            shape_similarity = 0.7 * circularity_sim + 0.3 * aspect_ratio_sim

            # LBP ç´‹ç†ç›¸ä¼¼åº¦
            lbp_similarity = self.calculate_lbp_similarity(uploaded_lbp, db_lbp)

            # ORB åˆ»å°ç›¸ä¼¼åº¦ï¼ˆå»¶é²è¨ˆç®—ï¼‰
            orb_similarity = 0.0
            if uploaded_orb is not None and color_similarity >= 0.3:
                image_path = self.photo_dir / record["image_filename"]
                db_orb = self._get_or_compute_orb(record["image_filename"], image_path)
                orb_similarity = self.calculate_orb_similarity(uploaded_orb, db_orb)

            # åˆ»ç—•æ–‡å­—ç›¸ä¼¼åº¦
            mark_similarity = 0.0
            if record.get("mark"):
                # é€™è£¡æš«æ™‚ä½¿ç”¨ 0ï¼Œå› ç‚ºä¸Šå‚³åœ–ç‰‡æ²’æœ‰åˆ»ç—•æ–‡å­—è³‡è¨Š
                # å¦‚æœæœªä¾†åŠ å…¥ OCR è­˜åˆ¥åˆ»ç—•æ–‡å­—ï¼Œå¯ä»¥åœ¨é€™è£¡æ¯”å°
                mark_similarity = 0.0

            # ç¶œåˆç›¸ä¼¼åº¦ï¼ˆå„ªåŒ–æ¬Šé‡é…ç½®ï¼‰
            # ç­–ç•¥ï¼šé¡è‰²å’Œå½¢ç‹€ä½œç‚ºä¸»è¦ç¯©é¸,ç´‹ç†å’Œåˆ»å°ä½œç‚ºç´°ç¯€è¾¨è­˜
            # é¡è‰² 0.40ï¼ˆå¤§å¹…æé«˜ï¼‰ï¼Œå½¢ç‹€ 0.30ï¼ˆæé«˜ï¼‰ï¼ŒLBPç´‹ç† 0.20ï¼ˆé™ä½ï¼‰ï¼ŒORBåˆ»å° 0.10ï¼ˆé™ä½ï¼‰

            # æ›´åš´æ ¼çš„æ‡²ç½°æ©Ÿåˆ¶
            # é¡è‰²ç›¸ä¼¼åº¦ä½æ–¼ 50% çµ¦äºˆé‡åº¦æ‡²ç½°
            if color_similarity < 0.35:
                color_penalty = 0.3  # å¤§å¹…é™ä½
            elif color_similarity < 0.5:
                color_penalty = 0.6
            else:
                color_penalty = 1.0

            # å½¢ç‹€ç›¸ä¼¼åº¦ä½æ–¼ 40% çµ¦äºˆæ‡²ç½°
            if shape_similarity < 0.3:
                shape_penalty = 0.5
            elif shape_similarity < 0.4:
                shape_penalty = 0.7
            else:
                shape_penalty = 1.0

            overall_similarity = (
                (
                    0.40 * color_similarity
                    + 0.30 * shape_similarity
                    + 0.20 * lbp_similarity
                    + 0.10 * orb_similarity
                )
                * color_penalty
                * shape_penalty
            )

            # éæ¿¾æ‰ç›¸ä¼¼åº¦å¤ªä½çš„çµæœï¼ˆä½æ–¼ 15% ç›´æ¥ä¸åˆ—å…¥ï¼‰
            if overall_similarity < 0.15:
                continue

            results.append(
                {
                    **record,
                    "similarity": float(overall_similarity),
                    "similarity_percent": f"{overall_similarity * 100:.1f}%",
                    "details": {
                        "color": f"{color_similarity * 100:.1f}%",
                        "shape": f"{shape_similarity * 100:.1f}%",
                        "texture": f"{lbp_similarity * 100:.1f}%",
                        "imprint": f"{orb_similarity * 100:.1f}%",
                    },
                }
            )

            # é¿å…å–®æ¬¡è«‹æ±‚æ²’æœ‰å›æ‡‰å¤ªä¹…ï¼Œå°å¤§å‹è³‡æ–™é›†æ¯è™•ç† 200 ç­†å°±æ‰“å°ä¸€æ¬¡é€²åº¦
            if idx % 200 == 0:
                elapsed = time.time() - t0
                print(f"â±ï¸ å·²æ¯”å° {idx} ç­†ï¼Œè€—æ™‚ {elapsed:.1f}s")
            if on_progress:
                try:
                    on_progress(idx, total_candidates)
                except Exception:
                    pass

        # æŒ‰ç›¸ä¼¼åº¦æ’åºä¸¦è¿”å›å‰ K å€‹
        results.sort(key=lambda x: x["similarity"], reverse=True)

        elapsed = time.time() - t0
        print(
            f"âœ… æ¯”å°å®Œæˆï¼šå€™é¸ {len(filtered_records)} â†’ å–å‰ {top_k}ï¼Œç¸½è€—æ™‚ {elapsed:.2f}s"
        )
        if on_progress:
            try:
                on_progress(total_candidates, total_candidates)
            except Exception:
                pass

        return results[:top_k]

    def recognize_prescription(self, uploaded_image_path: str) -> Dict:
        """
        è¾¨è­˜è—¥å–®ï¼ˆåŒ…å«å¤šå€‹è—¥ç‰©çš„åœ–ç‰‡ï¼‰

        Args:
            uploaded_image_path: ä¸Šå‚³çš„è—¥å–®åœ–ç‰‡è·¯å¾‘

        Returns:
            è¾¨è­˜çµæœï¼ŒåŒ…å«æª¢æ¸¬åˆ°çš„å¤šå€‹è—¥ç‰©
        """
        # è®€å–åœ–ç‰‡ï¼ˆæ”¯æ´ä¸­æ–‡è·¯å¾‘ï¼‰
        try:
            with open(uploaded_image_path, "rb") as f:
                image_data = f.read()
            nparr = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        except Exception as e:
            return {"success": False, "message": f"ç„¡æ³•è®€å–åœ–ç‰‡: {e}"}

        if img is None:
            return {"success": False, "message": "ç„¡æ³•è®€å–åœ–ç‰‡"}

        # è½‰ç‚ºç°éš
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # ä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
        )

        # å°‹æ‰¾è¼ªå»“ï¼ˆå¯èƒ½çš„è—¥ç‰©å€åŸŸï¼‰
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        # éæ¿¾å¤ªå°çš„è¼ªå»“
        min_area = 1000
        drug_regions = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]

        # å°æ¯å€‹å€åŸŸé€²è¡Œè¾¨è­˜
        detected_drugs = []

        for i, contour in enumerate(drug_regions[:10]):  # æœ€å¤šè™•ç† 10 å€‹å€åŸŸ
            # ç²å–é‚Šç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)

            # è£å‰ªè—¥ç‰©å€åŸŸ
            drug_roi = img[y : y + h, x : x + w]

            # å„²å­˜è‡¨æ™‚åœ–ç‰‡
            temp_path = f"temp_drug_{i}.jpg"
            cv2.imwrite(temp_path, drug_roi)

            # è¾¨è­˜è©²å€åŸŸ
            recognition_result = self.recognize_drug(temp_path, top_k=1)

            if recognition_result:
                detected_drugs.append(
                    {
                        "region": i + 1,
                        "position": {
                            "x": int(x),
                            "y": int(y),
                            "w": int(w),
                            "h": int(h),
                        },
                        "drug": recognition_result[0],
                    }
                )

            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            Path(temp_path).unlink(missing_ok=True)

        return {
            "success": True,
            "total_detected": len(detected_drugs),
            "drugs": detected_drugs,
        }


def test_recognition():
    """æ¸¬è©¦è¾¨è­˜åŠŸèƒ½"""
    recognizer = DrugImageRecognizer()

    # æ¸¬è©¦å–®è—¥ç‰©è¾¨è­˜
    test_image = "test_drug.jpg"  # æ›¿æ›ç‚ºå¯¦éš›æ¸¬è©¦åœ–ç‰‡è·¯å¾‘

    if Path(test_image).exists():
        print("é–‹å§‹è¾¨è­˜...")
        results = recognizer.recognize_drug(test_image, top_k=3)

        print(f"\næ‰¾åˆ° {len(results)} å€‹åŒ¹é…çµæœï¼š")
        for i, result in enumerate(results, 1):
            print(f"\nç¬¬ {i} åï¼š")
            print(f"  è—¥ç‰©åç¨±ï¼š{result['chinese_name']} ({result['english_name']})")
            print(f"  è¨±å¯è­‰å­—è™Ÿï¼š{result['license_number']}")
            print(f"  ç›¸ä¼¼åº¦ï¼š{result['similarity_percent']}")
    else:
        print(f"æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {test_image}")


def detect_image_type(image_path: str) -> str:
    """
    è‡ªå‹•åˆ¤æ–·åœ–ç‰‡é¡å‹

    Args:
        image_path: åœ–ç‰‡è·¯å¾‘

    Returns:
        'text': åŒ…å«å¤§é‡æ–‡å­—ï¼ˆè—¥å–®/è—¥è¢‹ï¼‰
        'object': å–®ä¸€ç‰©é«”ï¼ˆè—¥ç‰©ç…§ç‰‡ï¼‰
        'mixed': æ··åˆæˆ–ä¸ç¢ºå®š
    """
    try:
        # è®€å–åœ–ç‰‡
        with open(image_path, "rb") as f:
            image_data = f.read()
        nparr = np.frombuffer(image_data, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            return "mixed"

        # è½‰ç°éš
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # é‚Šç·£æª¢æ¸¬
        edges = cv2.Canny(gray, 50, 150)

        # è¨ˆç®—é‚Šç·£å¯†åº¦
        edge_density = np.sum(edges > 0) / edges.size

        # è¼ªå»“æª¢æ¸¬
        contours, _ = cv2.findContours(
            edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        # æ–‡å­—å€åŸŸé€šå¸¸æœ‰å¾ˆå¤šå°è¼ªå»“
        small_contours = sum(1 for c in contours if cv2.contourArea(c) < 500)

        # åˆ¤æ–·é‚è¼¯
        if edge_density > 0.15 and small_contours > 50:
            return "text"  # å¯èƒ½æ˜¯è—¥å–®/æ–‡ä»¶
        elif len(contours) < 10 and edge_density < 0.1:
            return "object"  # å¯èƒ½æ˜¯å–®ä¸€è—¥ç‰©
        else:
            return "mixed"  # ä¸ç¢ºå®š
    except Exception as e:
        print(f"åœ–ç‰‡é¡å‹åˆ¤æ–·å¤±æ•—: {e}")
        return "mixed"


if __name__ == "__main__":
    test_recognition()
